{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('sparksql').getOrCreate()\n",
    "df = spark.createDataFrame(sns.load_dataset('tips'))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('tips_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "#dame tres columnas filtro normal con dataFrame de spark\n",
    "df.filter(col('tip') > 2).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hacer el mismo filtro pero con sql\n",
    "spark.sql('SELECT * FROM tips_table WHERE tip > 2;').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+\n",
      "| day|    avg_total_bill|           avg_tip|\n",
      "+----+------------------+------------------+\n",
      "| Sun|21.409999999999997|3.2551315789473683|\n",
      "| Sat|20.441379310344825| 2.993103448275862|\n",
      "|Thur|17.682741935483868|2.7714516129032254|\n",
      "| Fri| 17.15157894736842| 2.734736842105263|\n",
      "+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#group by con Dataframes\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df.groupBy('day').agg(\n",
    "    avg('total_bill').alias('avg_total_bill'),\n",
    "    avg('tip').alias('avg_tip')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+\n",
      "| day|    avg_total_bill|           avg_tip|\n",
      "+----+------------------+------------------+\n",
      "| Sun|21.409999999999997|3.2551315789473683|\n",
      "| Sat|20.441379310344825| 2.993103448275862|\n",
      "|Thur|17.682741935483868|2.7714516129032254|\n",
      "| Fri| 17.15157894736842| 2.734736842105263|\n",
      "+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# con sql\n",
    "spark.sql('''\n",
    "          SELECT day, \n",
    "          avg(total_bill) as avg_total_bill,\n",
    "          avg(tip) as avg_tip\n",
    "          FROM tips_table\n",
    "          group by day;\n",
    "          ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+------+---+------+----+\n",
      "|total_bill| tip| sex|smoker|day|  time|size|\n",
      "+----------+----+----+------+---+------+----+\n",
      "|     50.81|10.0|Male|   Yes|Sat|Dinner|   3|\n",
      "|     48.33| 9.0|Male|    No|Sat|Dinner|   4|\n",
      "|     48.27|6.73|Male|    No|Sat|Dinner|   4|\n",
      "|     48.17| 5.0|Male|    No|Sun|Dinner|   6|\n",
      "|     45.35| 3.5|Male|   Yes|Sun|Dinner|   3|\n",
      "+----------+----+----+------+---+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(col('total_bill').desc()).limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+\n",
      "|total_bill| tip| sex|\n",
      "+----------+----+----+\n",
      "|     50.81|10.0|Male|\n",
      "|     48.33| 9.0|Male|\n",
      "|     48.27|6.73|Male|\n",
      "|     48.17| 5.0|Male|\n",
      "|     45.35| 3.5|Male|\n",
      "+----------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "          SELECT total_bill, tip, sex\n",
    "          FROM tips_table\n",
    "          ORDER BY total_bill DESC\n",
    "          LIMIT 5;\n",
    "          ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|          tip_ratio|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agregar una nueva columna\n",
    "from pyspark.sql.functions import expr\n",
    "df.withColumn('tip_ratio', expr('tip / total_bill')).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|          tip_ratio|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "          SELECT *,\n",
    "          tip / total_bill as tip_ratio\n",
    "          FROM tips_table;\n",
    "          ''').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|          tip_ratio|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- total_bill: double (nullable = true)\n",
      " |-- tip: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- size: long (nullable = true)\n",
      " |-- tip_ratio: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# en vez de hacer un show se puede hacer retornar a un dataframe directamente\n",
    "df_tips_ratio = spark.sql('''\n",
    "          SELECT *,\n",
    "          tip / total_bill as tip_ratio\n",
    "          FROM tips_table;\n",
    "          ''')\n",
    "\n",
    "df_tips_ratio.show(2)\n",
    "df_tips_ratio.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|tip_category|\n",
      "+----------+----+------+------+---+------+----+------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|        baja|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|        baja|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|        alta|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|        alta|\n",
      "+----------+----+------+------+---+------+----+------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df.withColumn('tip_category', when(col('tip') > 3, 'alta').otherwise('baja')).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|tip_category|\n",
      "+----------+----+------+------+---+------+----+------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|        baja|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|        baja|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|        alta|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|        alta|\n",
      "+----------+----+------+------+---+------+----+------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "          SELECT *,\n",
    "          CASE WHEN tip > 3 THEN 'alta' ELSE 'baja' END as tip_category \n",
    "          FROM tips_table;\n",
    "          ''').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+--------------+\n",
      "| day|  time|count_bookings|\n",
      "+----+------+--------------+\n",
      "| Sat|Dinner|            87|\n",
      "| Sun|Dinner|            76|\n",
      "|Thur| Lunch|            61|\n",
      "| Fri|Dinner|            12|\n",
      "| Fri| Lunch|             7|\n",
      "|Thur|Dinner|             1|\n",
      "+----+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#group by por dos campos\n",
    "from pyspark.sql.functions import count\n",
    "df.groupBy('day', 'time').agg(count('*').alias('count_bookings')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------------+\n",
      "| day|  time|count_booking|\n",
      "+----+------+-------------+\n",
      "| Sat|Dinner|           87|\n",
      "| Sun|Dinner|           76|\n",
      "|Thur| Lunch|           61|\n",
      "| Fri|Dinner|           12|\n",
      "| Fri| Lunch|            7|\n",
      "|Thur|Dinner|            1|\n",
      "+----+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "          SELECT day, time, count(*) as count_booking\n",
    "          FROM tips_table\n",
    "          GROUP BY day, time;\n",
    "          ''').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
